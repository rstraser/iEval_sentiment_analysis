---
title: 'What do your students think about you?'
subtitle: 'Using sentiment analysis to gain insight on student perceptions'
author: "Rob Straser"
date: "Feb. 11th, 2021"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      results = "hide",
                      message = FALSE,
                      warning = FALSE)
```

### What are teaching assistant course evaluations?

Graduate students often have the opportunity to be employed as a teaching assistants, or "TAs", to aid professors in lectures and course modules. Following the end of an academic quarter, undergraduate students participate in instructor evaluations to share feedback from their learning experience, and furthermore, evaluate their TA's effectiveness as an instructor of course. These evaluations typically include two components: (1) a numerical evaluation of a given criteria in which the student expresses the degree to which they agree or disagree (eg. TA was well organized for every lecture, etc.) and (2) a written evaluation where students can leave more personalized comments based on their impressions of the course and the TA.


### What is sentiment analysis?

Sentiment analysis is a data classification tool used to detect positive, negative or neutral sentiment underlying text. These analyses are often used in market research to better understand the attitudes, opinions, and emotions expressed by the public on a given topic over time and space.


### How does it work?

Sentiment analysis uses natural language processing and machine learning algorithems to identify emotional connotation underlying words and their association between one another. This processes generally focuses on word polarity (positive, negative, neutral), emotion (angry, sad, nervous, happy, etc.) or intention (interested or not interested).

### What will I be doing here?

While numerical values are easily evaluated (usually expressed as an average out of a total), written responses can be much more difficult to evaluate given the complexity of language structure. However, sentinment analysis may help identify some common trends found in these written responses to help elucide student perceptions of the TA. For this project, I will use the written evaluations from students across various courses I've taught over the last couple years as a graduate TA. Using sentiment analysis, I aim to address two primary questions:

> 1. What are the most frequent words used by students in their evaluations?
> 2. How are these words ranked in regards to their sentiment value?

### Let's dive in!

To help explore various methods in sentiment analysis, I will be using the following packages in R:
```{r}
# tidy tools
library(tidyverse)
library(tidytext)
library(stopwords)
library(textdata)

# extracting PDFs
library(pdftools)

# visualizations
library(ggplot2)
library(viridis)
library(wordcloud)
```

### Inputting and cleaning data

Next, I will input and clean the data. Sentiment analysis can be used on various formats containing written text. However, for my purposes, I will upload the written text data from its original PDF format.

```{r}
# read in PDF
ieval <- pdftools::pdf_text("data/iEval_Comments_concise.pdf") %>%
         readr::read_lines()
```

Prior to loading the data, I consolidated all written evaluations into a single PDF. This allowed unnessessry text generated from headings, instructions, questions, and numerical responses on the evaluation forms to be removed from the document. Next I will remove unnessessary 'whitespace' from the document and 'tokenize' the text to identify individual words contained in the document, arranging them by most frequently used.

```{r}
# text cleaning
iEval <-  ieval %>% 
          str_squish() %>% 
          as_tibble() %>% 
          rename(text = 1)%>% 
          unnest_tokens(word, text) %>%
          anti_join(get_stopwords(), by = "word") %>%
          group_by(word) %>% 
          count() %>% 
          ungroup() %>% 
          slice(-c(1:115)) %>%
          arrange(desc(n))
```


Data cleaning is a large part of the sentiment analysis process. There are many common words used that may hinder accurate translation in the sentiment analysis. These words can be removed from observation prior to the analysis. Here, I removed words 'rob' (my name), 'jeopardy' (an exam prep game I used frquently in my courses) and 'confused', which often came up as a non-negative (eg. "helped me when I was confused on a topic"). 

```{r}
# remove unwanted words
eval <- iEval %>%
        filter(str_detect(word, "rob", negate = TRUE)) %>%
        filter(str_detect(word, "jeopardy", negate = TRUE)) %>%
        filter(str_detect(word, "confused", negate = TRUE))
```

### Data analysis

There are various forms of sentiment analysis that differ in how they interpret the sentiment text. The three main forms are: 'bing', 'afinn', and 'nrc'. Each form of analysis differs slightly in it's evaluation of word sentiment and provides various classification scales (eg. positive - negative, sad - happy, etc.). In practice, using multiple forms of analysis may likely result in more robust evaluations of sentiment.

I will first use 'bing' to assess the most common 'positive' and 'negative' words used in my student evaluations, visualizing the data as barplots.

```{r}
# bing analysis
bing_word_counts <- eval %>%
                    inner_join(get_sentiments("bing")) %>%
                    ungroup()

# facet plot in descending order
bing_word_counts %>%
  group_by(sentiment) %>%
  slice_head(n = 15) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill = sentiment)) +
      scale_fill_viridis_d() + 
      geom_col(show.legend = FALSE) +
      facet_wrap(~sentiment, scales = "free_y") +
      labs(x = "Contribution to sentiment (bing)",
           y = NULL) +
      theme(panel.grid.major = element_blank(), 
            panel.grid.minor = element_blank(),
            panel.background = element_blank(), 
            axis.line = element_line(colour = "grey"))
  
```

Next I will use the 'afinn' analysis to observe the most commonly used words in my TA evaluations as ranked along a sentiment value gradient, visualized as descending barplots.

```{r}

# afinn analysis
afinn = get_sentiments("afinn")

eval.sentiments = eval %>% 
  inner_join(afinn, by = "word")

# plot descending order, color by value
eval.sentiments  %>%
  filter(n > 2) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(x = word, y = n, fill = value)) +
      scale_fill_viridis(option = "D") + 
      geom_col(alpha = .8) +
      coord_flip() +
      labs(y = "Contribution to sentiment (afinn)")+
      theme(panel.background = element_blank(), 
            panel.grid = element_blank(),
            legend.position = c(.75,.25))


```

Lastly, I will use the same data to visualize the relationship between the sentiment value of each commonly used word with the number of times that word was mentioned in the TA evaluations. Based on the previous observation, I would expect a positive trend given the majority of words used scored highly on the sentiment value scale under 'afinn'.

```{r}
# plot sentiment value ~ number of times word used, color by value
ggplot(eval.sentiments, aes(value, log10(n)))+
    geom_point(aes(color = value)) +
    geom_jitter(aes(color = value)) +
    scale_color_viridis(option = "D") +
    geom_smooth(method=lm, color="black", size=0.5) +
    labs(x = "Sentiment value (afinn)") +
    labs(y = "Log(word count)") +
    theme_classic()
  
```


There you have it! A fun exercise exploring the utility, and general concepts behind sentiment analysis (albeit just scratching the surface). Using sentiment analysis, I was able to gain an improved understanding to the underlying perceptions my students had on me as their course instructor. Furthermore, this processed allowed me to see which teaching traits had the greatest positive (or in some circumstances, negative) impact on my student's learning experience, providing me the opportunty to improve my teaching methods to become a more effective instructor.

Human language is complex, and even trained machine algorithms will have difficulty understanding the various nuances involved in grammar, slang, and context. Sentiment analysis is not perfect, and a lot of care must be taken to best interpret the results. However, despite these limitations, sentiment analyses can be a powerful tool for exploring underlying opinons and perceptions in complex written text.
